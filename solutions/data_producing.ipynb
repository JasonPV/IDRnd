{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "from IPython.display import Audio\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import logging\n",
    "from IPython.display import Audio\n",
    "\n",
    "from IDRnD.utils import *\n",
    "from IDRnD.augmentations import *\n",
    "from IDRnD.dataset import *\n",
    "from IDRnD.resnet import resnet50\n",
    "from IDRnD.focalloss import FocalLoss\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CyclicLR, ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "seed_everything(0)\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logs/logs.log\",\n",
    "                    filemode=\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_train_data()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    #RandomParameter(VTLP, [[0.8, 1.2]], p=0.5),\n",
    "    #MinMaxChunkScaler(),\n",
    "    #Normalize(),\n",
    "    #RandomParameter(RandomNoise, [[0.01, 0.1]]),\n",
    "    #RandomParameter(Shift, [[2000, 32000]]),\n",
    "    #RandomParameter(TimeStretch, [[0.75, 1.3]]),\n",
    "    #RandomParameter(PitchShift, [[-8, 8]]),\n",
    "    #RandomParameter(Distortion, [[-1, -0.3], [.3, 1.]]),\n",
    "    ToMellSpec(n_mels=128),\n",
    "    #GetMFCC(),\n",
    "    #PadOrClip(300),\n",
    "    #Normalize(),\n",
    "    #ToTensor(),\n",
    "    #transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Base_Dataset(X_train, y_train, train_transform)\n",
    "val_dataset = Base_Dataset(X_val, y_val, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_and_save_one_epoch(folder, run, dataset):\n",
    "    for sample in tqdm(range(len(dataset))):\n",
    "        k = dataset[sample][0]\n",
    "        name = f\"{run}_{sample}\"\n",
    "        path = os.path.join(folder, name)\n",
    "        np.save(path, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample(sample, dataset, run, folder):\n",
    "    k = dataset[sample][0]\n",
    "    name = f\"{run}_{sample}\"\n",
    "    path = os.path.join(folder, name)\n",
    "    np.save(path, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_and_save_one_epoch_parallel(run, folder, dataset):\n",
    "    before = time.time()\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        for sample in range(len(dataset)):\n",
    "            future = executor.submit(save_sample, sample, dataset, run, folder)\n",
    "    \n",
    "    print(time.time() - before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_and_save_one_epoch_joblib(run, folder, dataset):\n",
    "    Parallel(n_jobs=16, verbose=5, backend=\"multiprocessing\")(delayed(save_sample)(sample, dataset, run, folder)\n",
    "                        for sample in range(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../data/files/raw_mels\n",
    "!rm -rf ../data/files/raw_mels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../data/files/raw_mels\n",
    "!mkdir ../data/files/raw_mels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend MultiprocessingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done 112 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=16)]: Done 1012 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=16)]: Done 2272 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=16)]: Done 3892 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=16)]: Done 5872 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=16)]: Done 8212 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=16)]: Done 10912 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=16)]: Done 13972 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=16)]: Done 17392 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=16)]: Done 21127 tasks      | elapsed:   42.4s\n",
      "[Parallel(n_jobs=16)]: Done 23800 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=16)]: Done 27400 tasks      | elapsed:   55.7s\n",
      "[Parallel(n_jobs=16)]: Done 31288 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=16)]: Done 35464 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=16)]: Done 39412 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=16)]: Done 39526 out of 39526 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=16)]: Using backend MultiprocessingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done 144 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=16)]: Done 1404 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=16)]: Done 3168 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=16)]: Done 5436 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=16)]: Done 8208 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=16)]: Done 9882 out of 9882 | elapsed:   16.7s finished\n"
     ]
    }
   ],
   "source": [
    "for num in range(0, 1):\n",
    "    precalculate_and_save_one_epoch_joblib(num, \"../data/files/raw_mels\", train_dataset)\n",
    "    precalculate_and_save_one_epoch_joblib(num, \"../data/files/raw_mels_val\", val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
