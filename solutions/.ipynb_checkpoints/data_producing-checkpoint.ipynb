{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "from IPython.display import Audio\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import logging\n",
    "from IPython.display import Audio\n",
    "\n",
    "from IDRnD.utils import *\n",
    "from IDRnD.augmentations import *\n",
    "from IDRnD.dataset import *\n",
    "from IDRnD.resnet import resnet50\n",
    "from IDRnD.focalloss import FocalLoss\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CyclicLR, ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "seed_everything(0)\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logs/logs.log\",\n",
    "                    filemode=\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8420229020607687, 9.209471061281867)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_dataset[0][0]), np.std(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_train_data()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    #RandomParameter(VTLP, [[0.8, 1.2]], p=0.5),\n",
    "    #MinMaxChunkScaler(),\n",
    "    #Normalize(),\n",
    "    #RandomParameter(RandomNoise, [[0.01, 0.1]]),\n",
    "    #RandomParameter(Shift, [[2000, 32000]]),\n",
    "    #RandomParameter(TimeStretch, [[0.75, 1.3]]),\n",
    "    #RandomParameter(PitchShift, [[-8, 8]]),\n",
    "    #RandomParameter(Distortion, [[-1, -0.3], [.3, 1.]]),\n",
    "    #ToMellSpec(n_mels=128),\n",
    "    #GetMFCC(),\n",
    "    PadOrClip(320),\n",
    "    #Normalize(),\n",
    "    #ToTensor(),\n",
    "    #transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SimpleMelDataset(X, y, \"../data/files/raw_mels/\", train_transform)\n",
    "#val_dataset = Base_Dataset(X_val, y_val, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_and_save_one_epoch(folder, run, dataset):\n",
    "    for sample in tqdm(range(len(dataset))):\n",
    "        k = dataset[sample][0]\n",
    "        name = f\"{run}_{sample}\"\n",
    "        path = os.path.join(folder, name)\n",
    "        np.save(path, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample(sample, dataset, run, folder):\n",
    "    k = dataset[sample][0]\n",
    "    name = dataset.X[sample].split(\"/\")[-1].split(\".\")[0]\n",
    "    #name = f\"{run}_{sample}\"\n",
    "    path = os.path.join(folder, name)\n",
    "    np.save(path, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_and_save_one_epoch_parallel(run, folder, dataset):\n",
    "    before = time.time()\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        for sample in range(len(dataset)):\n",
    "            future = executor.submit(save_sample, sample, dataset, run, folder)\n",
    "    \n",
    "    print(time.time() - before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_and_save_one_epoch_joblib(run, folder, dataset):\n",
    "    Parallel(n_jobs=16, verbose=5, backend=\"multiprocessing\")(delayed(save_sample)(sample, dataset, run, folder)\n",
    "                        for sample in range(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../data/files/raw_mels\n",
    "!rm -rf ../data/files/raw_mels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../data/files/raw_mels\n",
    "#!mkdir ../data/files/raw_mels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend MultiprocessingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done 112 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=16)]: Done 1012 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=16)]: Done 2272 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=16)]: Done 3892 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=16)]: Done 5872 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=16)]: Done 8212 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=16)]: Done 10912 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=16)]: Done 13972 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=16)]: Done 17392 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=16)]: Done 20863 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=16)]: Done 24835 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=16)]: Done 29335 tasks      | elapsed:   58.1s\n",
      "[Parallel(n_jobs=16)]: Done 34195 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=16)]: Done 39415 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=16)]: Done 44308 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=16)]: Done 49408 out of 49408 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "for num in range(0, 1):\n",
    "    precalculate_and_save_one_epoch_joblib(num, \"../data/files/raw_mels\", train_dataset)\n",
    "    #precalculate_and_save_one_epoch_joblib(num, \"../data/files/raw_mels_val\", val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
