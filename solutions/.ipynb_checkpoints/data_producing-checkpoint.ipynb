{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "from IPython.display import Audio\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from Freesound.data import *\n",
    "from Freesound.utils import *\n",
    "from Freesound.model import *\n",
    "from Freesound.augmentations import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CyclicLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "seed_everything(0)\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logs/logs.log\", filemode=\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/src/workspace/data/files/\"\n",
    "train_dataset_dir = os.path.join(dataset_dir, \"Training_Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sorted(glob.glob(os.path.join(train_dataset_dir, '**/*.wav'), recursive=True))\n",
    "y = np.array([1 if \"human\" in i else 0 for i in X])\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    #RandomParameter(VTLP, [[0.8, 1.2]], p=0.5),\n",
    "    #MinMaxChunkScaler(),\n",
    "    #Normalize(),\n",
    "    #RandomParameter(RandomNoise, [[0.01, 0.1]]),\n",
    "    #RandomParameter(Shift, [[2000, 32000]]),\n",
    "    #RandomParameter(TimeStretch, [[0.75, 1.3]]),\n",
    "    #RandomParameter(PitchShift, [[-8, 8]]),\n",
    "    #RandomParameter(Distortion, [[-1, -0.3], [.3, 1.]]),\n",
    "    ToMellSpec(n_mels=128),\n",
    "    #GetMFCC(),\n",
    "    #PadOrClip(300),\n",
    "    #Normalize(),\n",
    "    #ToTensor(),\n",
    "    #transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-47465d5ea56f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset_Train(X_train, y_tr, train_transform)\n",
    "val_dataset = Dataset_Train(X_val, y, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_and_save_one_epoch(folder, run, dataset):\n",
    "    for sample in tqdm(range(len(dataset))):\n",
    "        k = dataset[sample][0]\n",
    "        name = f\"{run}_{sample}\"\n",
    "        path = os.path.join(folder, name)\n",
    "        np.save(path, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample(sample, dataset, run, folder):\n",
    "    k = dataset[sample][0]\n",
    "    name = f\"{run}_{sample}\"\n",
    "    path = os.path.join(folder, name)\n",
    "    np.save(path, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_and_save_one_epoch_parallel(run, folder, dataset):\n",
    "    before = time.time()\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        for sample in range(len(dataset)):\n",
    "            future = executor.submit(save_sample, sample, dataset, run, folder)\n",
    "    \n",
    "    print(time.time() - before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_and_save_one_epoch_joblib(run, folder, dataset):\n",
    "    Parallel(n_jobs=16, verbose=5, backend=\"multiprocessing\")(delayed(save_sample)(sample, dataset, run, folder)\n",
    "                        for sample in range(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../data/files/raw_mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../data/files/raw_mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend MultiprocessingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  64 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=16)]: Done 424 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=16)]: Done 928 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=16)]: Done 1576 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=16)]: Done 2368 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=16)]: Done 3304 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=16)]: Done 4384 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=16)]: Done 5608 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=16)]: Done 6976 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=16)]: Done 8488 tasks      | elapsed:   51.0s\n",
      "[Parallel(n_jobs=16)]: Done 10144 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=16)]: Done 11944 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=16)]: Done 13888 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=16)]: Done 15976 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=16)]: Done 18208 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=16)]: Done 20584 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=16)]: Done 23104 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=16)]: Done 25768 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=16)]: Done 28576 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=16)]: Done 31528 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=16)]: Done 34624 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=16)]: Done 37864 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=16)]: Done 41248 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=16)]: Done 44776 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=16)]: Done 48448 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=16)]: Done 50000 out of 50000 | elapsed:  4.8min finished\n"
     ]
    }
   ],
   "source": [
    "for num in range(0, 1):\n",
    "    precalculate_and_save_one_epoch_joblib(num, \"../data/files/raw_mels\", train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
