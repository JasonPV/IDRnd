{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "from IPython.display import Audio\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from Freesound.data import *\n",
    "from Freesound.utils import *\n",
    "from Freesound.model import *\n",
    "from Freesound.augmentations import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CyclicLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "seed_everything(0)\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logs/logs.log\", filemode=\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/src/workspace/data/files/\"\n",
    "train_dataset_dir = os.path.join(dataset_dir, \"Training_Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sorted(glob.glob(os.path.join(train_dataset_dir, '**/*.wav'), recursive=True))\n",
    "y = np.array([1 if \"human\" in i else 0 for i in X])\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    #RandomParameter(VTLP, [[0.8, 1.2]], p=0.5),\n",
    "    #MinMaxChunkScaler(),\n",
    "    #Normalize(),\n",
    "    #RandomParameter(RandomNoise, [[0.01, 0.1]]),\n",
    "    #RandomParameter(Shift, [[2000, 32000]]),\n",
    "    #RandomParameter(TimeStretch, [[0.75, 1.3]]),\n",
    "    #RandomParameter(PitchShift, [[-8, 8]]),\n",
    "    #RandomParameter(Distortion, [[-1, -0.3], [.3, 1.]]),\n",
    "    ToMellSpec(n_mels=128),\n",
    "    #GetMFCC(),\n",
    "    #PadOrClip(300),\n",
    "    #Normalize(),\n",
    "    #ToTensor(),\n",
    "    #transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset_Train(X, y, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_and_save_one_epoch(folder, run, dataset):\n",
    "    for sample in tqdm(range(len(dataset))):\n",
    "        k = dataset[sample][0]\n",
    "        name = f\"{run}_{sample}\"\n",
    "        path = os.path.join(folder, name)\n",
    "        np.save(path, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample(sample, dataset, run, folder):\n",
    "    k = dataset[sample][0]\n",
    "    name = f\"{run}_{sample}\"\n",
    "    path = os.path.join(folder, name)\n",
    "    np.save(path, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_and_save_one_epoch_parallel(run, folder, dataset):\n",
    "    before = time.time()\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        for sample in range(len(dataset)):\n",
    "            future = executor.submit(save_sample, sample, dataset, run, folder)\n",
    "    \n",
    "    print(time.time() - before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate_and_save_one_epoch_joblib(run, folder, dataset):\n",
    "    Parallel(n_jobs=16, verbose=5, backend=\"multiprocessing\")(delayed(save_sample)(sample, dataset, run, folder)\n",
    "                        for sample in range(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../data/raw_mels_augs_RT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../data/files/raw_mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend MultiprocessingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  40 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=16)]: Done 130 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=16)]: Done 256 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:   56.8s\n",
      "[Parallel(n_jobs=16)]: Done 616 tasks      | elapsed:  1.4min\n"
     ]
    }
   ],
   "source": [
    "for num in range(0, 1):\n",
    "    precalculate_and_save_one_epoch_joblib(num, \"../data/files/raw_mels\", train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
