{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "from IPython.display import Audio\n",
    "\n",
    "from IDRnD.utils import *\n",
    "from IDRnD.augmentations import *\n",
    "from IDRnD.dataset import *\n",
    "from IDRnD.resnet import *\n",
    "from IDRnD.nasnet_mobile import NASNetAMobile\n",
    "from IDRnD.focalloss import FocalLoss\n",
    "from IDRnD.callbacks import *\n",
    "from IDRnD.pipeline import *\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CyclicLR, ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "seed_everything(0)\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logs/logs.log\",\n",
    "                    filemode=\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_transform = transforms.Compose([\n",
    "    librosa.power_to_db,\n",
    "    PadOrClip(320),\n",
    "    Normalize_predef(-29.6179, 16.6342),\n",
    "    ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 435\n",
    "thresh = 0.001\n",
    "\n",
    "criterion = nn.BCELoss().cuda()\n",
    "optimizer = Adam(params=model.parameters(), lr=1e-4)\n",
    "\n",
    "tb_logger = TensorBoardCallback(compute_eer)\n",
    "saver = SaveEveryEpoch(\"models/resnet_34_finding_best_val.pt\")\n",
    "best = SaveBestEpoch(\"models/resnet_34_finding_best_val.pt\", compute_eer)\n",
    "hm = Train(callbacks=[tb_logger, saver, best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mask = np.load(\"IDRnD/data/mask.npy\")\\nX_good, X_bad, y_good, y_bad = X_val[np.invert(mask)], X_val[mask], y_val[np.invert(mask)], y_val[mask]\\nX_train_new, y_train_new = np.concatenate((X_train, X_bad)), np.concatenate((y_train, y_bad))\\nX_val_new, y_val_new = X_good, y_good\\n\\nX, y = np.concatenate((X_train_new, common_X, pathes_old_competition)), np.concatenate((y_train_new, common_y, classes_old_competition))'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = get_train_data()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\"\"\"mask = np.load(\"IDRnD/data/mask.npy\")\n",
    "X_good, X_bad, y_good, y_bad = X_val[np.invert(mask)], X_val[mask], y_val[np.invert(mask)], y_val[mask]\n",
    "X_train_new, y_train_new = np.concatenate((X_train, X_bad)), np.concatenate((y_train, y_bad))\n",
    "X_val_new, y_val_new = X_good, y_good\n",
    "\n",
    "X, y = np.concatenate((X_train_new, common_X, pathes_old_competition)), np.concatenate((y_train_new, common_y, classes_old_competition))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SimpleMelDataset(X_train, y_train, \"../data/files/raw_mels/\", post_transform)\n",
    "valid_dataset = SimpleMelDataset(X_val, y_val, \"../data/files/raw_mels/\", post_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size*3, num_workers=16, shuffle=False)\n",
    "\n",
    "model = resnet34(num_classes=1).cuda()\n",
    "state = torch.load(\"models/resnet34-333f7ec4.pth\")#'models/resnet34-333f7ec4.pth')\n",
    "state.pop(\"conv1.weight\")\n",
    "state.pop(\"fc.weight\")\n",
    "state.pop(\"fc.bias\")\n",
    "model.load_state_dict(state, strict=False)\n",
    "model_dst = torch.nn.DataParallel(model, device_ids=[0, 1]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger = TensorBoardCallback(compute_eer)\n",
    "saver = SaveEveryEpoch(\"models/resnet_34_finding_best_val.pt\")\n",
    "best = SaveBestEpoch(\"models/resnet_34_finding_best_val.pt\", compute_eer)\n",
    "hm = Train(callbacks=[tb_logger, saver, best])\n",
    "\n",
    "hm.fit(train_loader, valid_loader, model_dst, criterion, optimizer, epoches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet34(num_classes=1).cuda()\n",
    "state = torch.load(\"models/resnet_34_finding_best_val.pt4\")\n",
    "model.load_state_dict(state, strict=True)\n",
    "model_dst = torch.nn.DataParallel(model, device_ids=[0, 1]).cuda()\n",
    "preds = hm.predict_on_test(valid_loader, model_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f08cc2fbcc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEFBJREFUeJzt3H+QXWV9x/H3V1YU8Qdo6g6TpF0cY2uU6cjsINYZuxoHAnYIf0AnDtboZJoZS621TFts/0hHZUbaUqqMP5oaanSogNRpMkJLGeCObaeJglgQKEMKKUSoaBPSRuqP6Ld/3Ce6pLvZs9m9d7l836+ZzJ7znOec83x3N/u55znn3shMJEn1PGepByBJWhoGgCQVZQBIUlEGgCQVZQBIUlEGgCQVZQBIUlEGgCQVZQBIUlFjSz2Ao1m2bFlOTEwc8/7f/e53OfHEExdvQM9w1eoFa67Cmufnzjvv/E5m/sxc/Z7RATAxMcEdd9xxzPv3ej2mpqYWb0DPcNXqBWuuwprnJyL+o0s/p4AkqSgDQJKKMgAkqSgDQJKKMgAkqSgDQJKKMgAkqSgDQJKKMgAkqahndQDc880DTFx641IPQ5KekZ7VASBJmp0BIElFGQCSVJQBIElFGQCSVJQBIElFGQCSVJQBIElFGQCSVJQBIElFGQCSVJQBIElFGQCSVJQBIElFGQCSVJQBIElFGQCSVJQBIElFGQCSVJQBIElFGQCSVJQBIElFGQCSVJQBIElFdQqAiHh/RNwbEd+IiM9HxPMj4tSI2BURD0bEdRFxfOv7vLa+u22fmHacD7T2ByLi7MGUJEnqYs4AiIjlwG8Bk5n5WuA4YD1wOXBlZq4C9gMb2y4bgf2Z+UrgytaPiFjd9nsNsBb4REQct7jlSJK66joFNAacEBFjwAuAx4G3ADe07duA89vyurZO274mIqK1X5uZ38/Mh4HdwBkLL0GSdCzG5uqQmd+MiD8FHgH+F/gH4E7gycw81LrtBZa35eXAo23fQxFxAHhZa9857dDT9/mJiNgEbAIYHx+n1+vNv6pm/AS45LRDCzrGKDl48GCZWg+z5hqseTDmDICIOJn+q/dTgSeBLwDnzNA1D+8yy7bZ2p/ekLkF2AIwOTmZU1NTcw1xVldds50r7hljz0XHfoxR0uv1WMj3axRZcw3WPBhdpoDeCjycmd/OzB8CXwR+CTipTQkBrAAea8t7gZUAbftLgH3T22fYR5I0ZF0C4BHgzIh4QZvLXwPcB9wOXND6bAC2t+UdbZ22/bbMzNa+vj0ldCqwCvjK4pQhSZqvLvcAdkXEDcDXgEPAXfSnaG4Ero2ID7e2rW2XrcDnImI3/Vf+69tx7o2I6+mHxyHg4sz80SLXI0nqaM4AAMjMzcDmI5ofYoaneDLze8CFsxznMuCyeY5RkjQAvhNYkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkorqFAARcVJE3BAR/xYR90fEGyLipRFxS0Q82L6e3PpGRHwsInZHxN0Rcfq042xo/R+MiA2DKkqSNLeuVwAfBf4+M38B+EXgfuBS4NbMXAXc2tYBzgFWtX+bgE8CRMRLgc3A64EzgM2HQ0OSNHxzBkBEvBh4E7AVIDN/kJlPAuuAba3bNuD8trwO+Gz27QROiohTgLOBWzJzX2buB24B1i5qNZKkzrpcAbwC+DbwVxFxV0R8OiJOBMYz83GA9vXlrf9y4NFp++9tbbO1S5KWwFjHPqcD783MXRHxUX463TOTmKEtj9L+9J0jNtGfOmJ8fJxer9dhiDMbPwEuOe3Qgo4xSg4ePFim1sOsuQZrHowuAbAX2JuZu9r6DfQD4FsRcUpmPt6meJ6Y1n/ltP1XAI+19qkj2ntHniwztwBbACYnJ3NqaurILp1ddc12rrhnjD0XHfsxRkmv12Mh369RZM01WPNgzDkFlJn/CTwaET/fmtYA9wE7gMNP8mwAtrflHcA729NAZwIH2hTRzcBZEXFyu/l7VmuTJC2BLlcAAO8FromI44GHgHfTD4/rI2Ij8AhwYet7E3AusBt4qvUlM/dFxIeAr7Z+H8zMfYtShSRp3joFQGZ+HZicYdOaGfomcPEsx7kauHo+A5QkDYbvBJakogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSrKAJCkogwASSqqcwBExHERcVdEfKmtnxoRuyLiwYi4LiKOb+3Pa+u72/aJacf4QGt/ICLOXuxiJEndzecK4H3A/dPWLweuzMxVwH5gY2vfCOzPzFcCV7Z+RMRqYD3wGmAt8ImIOG5hw5ckHatOARARK4C3AZ9u6wG8BbihddkGnN+W17V12vY1rf864NrM/H5mPgzsBs5YjCIkSfPX9Qrgz4HfA37c1l8GPJmZh9r6XmB5W14OPArQth9o/X/SPsM+kqQhG5urQ0T8CvBEZt4ZEVOHm2fomnNsO9o+08+3CdgEMD4+Tq/Xm2uIsxo/AS457dCCjjFKDh48WKbWw6y5BmsejDkDAHgjcF5EnAs8H3gx/SuCkyJirL3KXwE81vrvBVYCeyNiDHgJsG9a+2HT9/mJzNwCbAGYnJzMqampYyir76prtnPFPWPsuejYjzFKer0eC/l+jSJrrsGaB2POKaDM/EBmrsjMCfo3cW/LzIuA24ELWrcNwPa2vKOt07bflpnZ2te3p4ROBVYBX1m0SiRJ89LlCmA2vw9cGxEfBu4Ctrb2rcDnImI3/Vf+6wEy896IuB64DzgEXJyZP1rA+SVJCzCvAMjMHtBryw8xw1M8mfk94MJZ9r8MuGy+g5QkLT7fCSxJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklTUnAEQESsj4vaIuD8i7o2I97X2l0bELRHxYPt6cmuPiPhYROyOiLsj4vRpx9rQ+j8YERsGV5YkaS5drgAOAZdk5quBM4GLI2I1cClwa2auAm5t6wDnAKvav03AJ6EfGMBm4PXAGcDmw6EhSRq+OQMgMx/PzK+15f8B7geWA+uAba3bNuD8trwO+Gz27QROiohTgLOBWzJzX2buB24B1i5qNZKkzsbm0zkiJoDXAbuA8cx8HPohEREvb92WA49O221va5ut/chzbKJ/5cD4+Di9Xm8+Q3ya8RPgktMOLegYo+TgwYNlaj3Mmmuw5sHoHAAR8ULgb4Dfzsz/johZu87Qlkdpf3pD5hZgC8Dk5GROTU11HeL/c9U127ninjH2XHTsxxglvV6PhXy/RpE112DNg9HpKaCIeC79P/7XZOYXW/O32tQO7esTrX0vsHLa7iuAx47SLklaAl2eAgpgK3B/Zv7ZtE07gMNP8mwAtk9rf2d7GuhM4ECbKroZOCsiTm43f89qbZKkJdBlCuiNwK8B90TE11vbHwAfAa6PiI3AI8CFbdtNwLnAbuAp4N0AmbkvIj4EfLX1+2Bm7luUKiRJ8zZnAGTmPzHz/D3Amhn6J3DxLMe6Grh6PgOUJA2G7wSWpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKIMAEkqygCQpKKGHgARsTYiHoiI3RFx6bDPL0nqG2oARMRxwMeBc4DVwNsjYvWgzztx6Y1MXHrjoE8jSSNl2FcAZwC7M/OhzPwBcC2wblgnNwgk6afGhny+5cCj09b3Aq8f8hg6h8Cej7xtwCORpKc7/PfpM2tPHPi5hh0AMUNbPq1DxCZgU1s9GBEPLOB8y4DvHOvOcfkCzrw0FlTviLLmGsrV/ObLF1Tzz3XpNOwA2AusnLa+AnhseofM3AJsWYyTRcQdmTm5GMcaBdXqBWuuwpoHY9j3AL4KrIqIUyPieGA9sGPIY5AkMeQrgMw8FBG/CdwMHAdcnZn3DnMMkqS+YU8BkZk3ATcN6XSLMpU0QqrVC9ZchTUPQGTm3L0kSc86fhSEJBU18gEw10dLRMTzIuK6tn1XREwMf5SLq0PNvxMR90XE3RFxa0R0eiTsmazrR4hExAURkREx8k+MdKk5In61/azvjYi/HvYYF1uH3+2fjYjbI+Ku9vt97lKMc7FExNUR8UREfGOW7RERH2vfj7sj4vRFHUBmjuw/+jeS/x14BXA88K/A6iP6/Abwqba8Hrhuqcc9hJrfDLygLb+nQs2t34uALwM7gcmlHvcQfs6rgLuAk9v6y5d63EOoeQvwnra8Gtiz1ONeYM1vAk4HvjHL9nOBv6P/HqozgV2Lef5RvwLo8tES64BtbfkGYE1EzPSGtFExZ82ZeXtmPtVWd9J/v8Uo6/oRIh8C/hj43jAHNyBdav514OOZuR8gM58Y8hgXW5eaE3hxW34JR7yPaNRk5peBfUfpsg74bPbtBE6KiFMW6/yjHgAzfbTE8tn6ZOYh4ADwsqGMbjC61DzdRvqvIEbZnDVHxOuAlZn5pWEObIC6/JxfBbwqIv45InZGxNqhjW4wutT8R8A7ImIv/acJ3zucoS2Z+f5/n5ehPwa6yOb8aImOfUZJ53oi4h3AJPDLAx3R4B215oh4DnAl8K5hDWgIuvycx+hPA03Rv8r7x4h4bWY+OeCxDUqXmt8OfCYzr4iINwCfazX/ePDDWxID/fs16lcAc360xPQ+ETFG/7LxaJdcz3RdaiYi3gr8IXBeZn5/SGMblLlqfhHwWqAXEXvoz5XuGPEbwV1/t7dn5g8z82HgAfqBMKq61LwRuB4gM/8FeD79zwl6tur0//1YjXoAdPloiR3AhrZ8AXBbtrsrI2rOmtt0yF/Q/+M/6vPCMEfNmXkgM5dl5kRmTtC/73FeZt6xNMNdFF1+t/+W/g1/ImIZ/Smhh4Y6ysXVpeZHgDUAEfFq+gHw7aGOcrh2AO9sTwOdCRzIzMcX6+AjPQWUs3y0RER8ELgjM3cAW+lfJu6m/8p//dKNeOE61vwnwAuBL7T73Y9k5nlLNugF6ljzs0rHmm8GzoqI+4AfAb+bmf+1dKNemI41XwL8ZUS8n/5UyLtG+QVdRHye/hTesnZfYzPwXIDM/BT9+xznAruBp4B3L+r5R/h7J0lagFGfApIkHSMDQJKKMgAkqSgDQJKKMgAkqSgDQJKKMgAkqSgDQJKK+j/FNu6IyvtXOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = preds.index.tolist()\n",
    "indexes = [int(idx) for idx in index]\n",
    "preds[\"abs_diff\"] = np.abs(preds[0] - indexes)\n",
    "preds[\"abs_diff\"].hist(bins=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['names'] = X_val\n",
    "del_from_validation = set(np.array(preds[\"names\"][preds[\"abs_diff\"] < thresh]))\n",
    "mask = np.array([True if item in del_from_validation else False for item in X_val])\n",
    "X_good, X_bad, y_good, y_bad = X_val[np.invert(mask)], X_val[mask], y_val[np.invert(mask)], y_val[mask]\n",
    "X_train_new, y_train_new = np.concatenate((X_train, X_bad)), np.concatenate((y_train, y_bad))\n",
    "X_white_list, y_white_list = X_good, y_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_new, y_train_new, test_size=0.2, random_state=42, stratify=y_train_new)\n",
    "X_val, y_val = np.concatenate((X_val, X_white_list)), np.concatenate((y_val, y_white_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
