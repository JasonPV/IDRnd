{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "from IPython.display import Audio\n",
    "\n",
    "from IDRnD.utils import *\n",
    "from IDRnD.augmentations import *\n",
    "from IDRnD.dataset import *\n",
    "from IDRnD.resnet import *\n",
    "from IDRnD.nasnet_mobile import NASNetAMobile\n",
    "from IDRnD.focalloss import FocalLoss\n",
    "from IDRnD.callbacks import *\n",
    "from IDRnD.pipeline import *\n",
    "from IDRnD.mobilenet import *\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CyclicLR, ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "seed_everything(0)\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"logs/logs.log\",\n",
    "                    filemode=\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_transform = transforms.Compose([\n",
    "    librosa.power_to_db,\n",
    "    PadOrClip(320),\n",
    "    Normalize_predef(-29.6179, 16.6342),\n",
    "    ToTensor(),\n",
    "    #transforms.ToTensor(),\n",
    "    #lambda x: x.view(-1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base, y_base = get_train_data(True)\n",
    "#common_X, common_y = get_common_voices()\n",
    "pathes_old_competition, classes_old_competition = get_old_competition_dataset(False)\n",
    "\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, y_train, X_val, y_val = np.load(\"IDRnD/data/four_cicle_loop_validation.npy\", allow_pickle=True)\n",
    "\n",
    "#mask = np.load(\"IDRnD/data/mask.npy\")\n",
    "#X_good, X_bad, y_good, y_bad = X_val[np.invert(mask)], X_val[mask], y_val[np.invert(mask)], y_val[mask]\n",
    "#X_train_new, y_train_new = np.concatenate((X_train, X_bad)), np.concatenate((y_train, y_bad))\n",
    "#X_val_new, y_val_new = X_good, y_good\n",
    "\n",
    "#X, y = np.concatenate((common_X, pathes_old_competition)), np.concatenate((common_y, classes_old_competition))\n",
    "clusters=pd.read_csv(\"IDRnD/data/clusters_resnet.csv\")[\"cluster\"].values\n",
    "white_list = np.load(\"IDRnD/data/white_list.npy\")\n",
    "clusters = clusters[white_list]\n",
    "X, y = pathes_old_competition, classes_old_competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf experiments\n",
    "from mag.experiment import Experiment\n",
    "from IDRnD.dimka.networks.classifiers import TwoDimensionalCNNClassificationModel\n",
    "\n",
    "with Experiment({\n",
    "    \"data\": {\n",
    "        \"_input_dim\": 64,\n",
    "        \"_kfold_seed\": 42,\n",
    "        \"_n_folds\": 5,\n",
    "        \"_train_data_dir\": \"data/Training_Data/\",\n",
    "        \"_train_df\": \"data/train_df.csv\",\n",
    "        \"features\": \"mel_1024_512_64\",\n",
    "        \"max_audio_length\": 3,\n",
    "        \"p_aug\": 0.3,\n",
    "        \"p_mixup\": 0.0\n",
    "    },\n",
    "    \"label\": \"2d_cnn\",\n",
    "    \"network\": {\n",
    "        \"aggregation_type\": \"max\",\n",
    "        \"conv_base_depth\": 32,\n",
    "        \"growth_rate\": 1.3,\n",
    "        \"num_conv_blocks\": 5,\n",
    "        \"output_dropout\": 0.5,\n",
    "        \"start_deep_supervision_on\": 2\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"_save_every\": 5,\n",
    "        \"accumulation_steps\": 1,\n",
    "        \"batch_size\": 50,\n",
    "        \"epochs\": 7,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"scheduler\": \"1cycle_0.0001_0.005\",\n",
    "        \"switch_off_augmentations_on\": 6,\n",
    "        \"weight_decay\": 0.0\n",
    "    }\n",
    "}) as experiment:\n",
    "    device = \"cuda\"\n",
    "    config = experiment.config\n",
    "    model = TwoDimensionalCNNClassificationModel(experiment, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Done!\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-08.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 300\n",
    "\n",
    "for i in range(5):\n",
    "    upper, down = (i+1)*20, 20*i\n",
    "    down_ = clusters >= down\n",
    "    upper_ = clusters < upper\n",
    "    mask = down_ & upper_\n",
    "    X_train, y_train, X_val, y_val = X_base[~mask], y_base[~mask], X_base[mask], y_base[mask]\n",
    "    \n",
    "    state = torch.load('models/dimka_common_and_old.pt')\n",
    "    model.load_state_dict(state)\n",
    "    \n",
    "    train_dataset = SimpleMelDataset(X_train, y_train, \"../data/files/raw_mels/\", post_transform)\n",
    "    valid_dataset = SimpleMelDataset(X_val, y_val, \"../data/files/raw_mels/\", post_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=16, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size*3, num_workers=16, shuffle=False)\n",
    "    model_dst = torch.nn.DataParallel(model, device_ids=[0, 1]).cuda()\n",
    "\n",
    "    criterion = nn.BCELoss().cuda()\n",
    "    #criterion = FocalLoss(gamma=2, reduce='mean').cuda()\n",
    "    optimizer = Adam(params=model.parameters(), lr=1e-4)\n",
    "\n",
    "    tb_logger = TensorBoardCallback(compute_eer)\n",
    "    last = SaveLastEpoch(\"models/temp.pt\")\n",
    "    acumulator = AccumulateGradient([30, 50, 70, 100])\n",
    "    best = SaveBestEpoch(f\"models/dimka_model_from_pretrain_fold_{i}.pt\", compute_eer)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, patience=1, verbose=True)\n",
    "    scheduler_call = EpochScheduler(scheduler)\n",
    "    hm = Train(callbacks=[tb_logger, acumulator, best, scheduler_call, last])\n",
    "    hm.fit(train_loader, valid_loader, model_dst, criterion, optimizer, epoches=70)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "true, preds = None, None\n",
    "batch_size = 300\n",
    "for i in range(5):\n",
    "    upper, down = (i+1)*20, 20*i\n",
    "    down_ = clusters >= down\n",
    "    upper_ = clusters < upper\n",
    "    mask = down_ & upper_\n",
    "    X_train, y_train, X_val, y_val = X_base[~mask], y_base[~mask], X_base[mask], y_base[mask]\n",
    "    \n",
    "    state = torch.load(f'models/dimka_model_from_pretrain_fold_{i}.pt')\n",
    "    model.load_state_dict(state)\n",
    "\n",
    "    valid_dataset = SimpleMelDataset(X_val, y_val, \"../data/files/raw_mels/\", post_transform)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size*3, num_workers=16, shuffle=False)\n",
    "    model_dst = torch.nn.DataParallel(model, device_ids=[0, 1]).cuda()\n",
    "    pred = hm.predict_on_test(valid_loader, model_dst).values\n",
    "    \n",
    "    if true is None:\n",
    "        true, preds = y_val, pred\n",
    "    else:\n",
    "        true, preds = np.concatenate((true, y_val)), np.concatenate((preds, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train\n",
    "batch_size = 300\n",
    "\n",
    "#train_dataset = BaseDataset(pathes_old_competition[:-1000], classes_old_competition[:-1000], post_transform)# pathes_old_competition\n",
    "#valid_dataset = BaseDataset(pathes_old_competition[-1000:], classes_old_competition[-1000:], post_transform)# pathes_old_competition\n",
    "train_dataset = SimpleMelDataset(X, y, \"../data/files/raw_mels/\", post_transform)\n",
    "valid_dataset = SimpleMelDataset(X_base, y_base, \"../data/files/raw_mels/\", post_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size*3, num_workers=16, shuffle=False)\n",
    "\n",
    "#model = resnet34(num_classes=1).cuda()\n",
    "#model = mobilenetv2(num_classes=1, input_size=128).cuda()\n",
    "#state = torch.load('models/resnet_34_four_cicle_validation.pt')\n",
    "#state.pop(\"conv1.weight\")\n",
    "#state.pop(\"fc.weight\")\n",
    "#state.pop(\"fc.bias\")\n",
    "#model.load_state_dict(state, strict=False)\n",
    "model_dst = torch.nn.DataParallel(model, device_ids=[0, 1]).cuda()\n",
    "\n",
    "criterion = nn.BCELoss().cuda()\n",
    "#criterion = FocalLoss(gamma=2, reduce='mean').cuda()\n",
    "optimizer = Adam(params=model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-08.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-55e252619c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mhm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macumulator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mhm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/src/workspace/solutions/IDRnD/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, val_loader, model, criterion, optimizer, epoches)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtr_cnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mtr_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tb_logger = TensorBoardCallback(compute_eer)\n",
    "#saver = SaveEveryEpoch(\"models/resnet_34_common_voice.pt\")\n",
    "last = SaveLastEpoch(\"models/temp.pt\")\n",
    "acumulator = AccumulateGradient([30, 50, 70, 100])\n",
    "best = SaveBestEpoch(\"models/dimka_common_and_old.pt\", compute_eer)\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=1, verbose=True)\n",
    "scheduler_call = EpochScheduler(scheduler)\n",
    "hm = Train(callbacks=[tb_logger, acumulator, best, scheduler_call, last])\n",
    "\n",
    "hm.fit(train_loader, valid_loader, model_dst, criterion, optimizer, epoches=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
